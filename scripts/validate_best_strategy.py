#!/usr/bin/env python
"""
æœ€ä¼˜ç­–ç•¥éªŒè¯ä¸é•¿æœŸå›æµ‹è„šæœ¬

åŠŸèƒ½ï¼š
1. éªŒè¯æ¨èé…ç½®åœ¨ä¸åŒæ—¶æœŸçš„è¡¨ç°
2. å¯¹æ¯”åŸºå‡†æŒ‡æ•°ï¼ˆæ²ªæ·±300ã€ä¸­è¯500ç­‰ï¼‰
3. ç”Ÿæˆè¯¦ç»†çš„è°ƒä»“æŒ‡å—
4. è§£é‡Šä¸ºä»€ä¹ˆè¯¥ç­–ç•¥è¡¨ç°æœ€å¥½

ä½¿ç”¨æ–¹æ³•ï¼š
    python scripts/validate_best_strategy.py --strategy twelve-minus-one --period 10y
    python scripts/validate_best_strategy.py --compare-all  # å¯¹æ¯”æ‰€æœ‰ç­–ç•¥
"""

import sys
import os
from pathlib import Path
from datetime import datetime, timedelta
from typing import Dict, List, Tuple, Any
import argparse

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = Path(__file__).resolve().parent.parent
sys.path.insert(0, str(project_root))

import pandas as pd
import numpy as np

from momentum_cli.analysis import analyze, AnalysisConfig
from momentum_cli.analysis_presets import ANALYSIS_PRESETS, refresh_analysis_presets


# ============= é…ç½® =============

# æ¨èé…ç½®ï¼ˆæ¥è‡ªä½ çš„æµ‹è¯•ç»“æœï¼‰
RECOMMENDED_CONFIG = {
    "strategy": "twelve-minus-one",
    "frequency": "monthly",
    "top_n": 2,
    "observation_period": 2,
    "correlation_threshold": 0.70,
}

# åŸºå‡†æŒ‡æ•°
BENCHMARK_CODES = {
    "æ²ªæ·±300": "510300.XSHG",
    "ä¸­è¯500": "510500.XSHG",
    "ä¸­è¯1000": "512260.XSHG",
    "åˆ›ä¸šæ¿50": "159949.XSHE",
}

# ETFå€™é€‰æ± 
ALL_CODES = [
    "510300.XSHG", "510880.XSHG", "511360.XSHG", "518880.XSHG", "513500.XSHG",
    "512980.XSHG", "512170.XSHG", "512690.XSHG", "512480.XSHG", "515790.XSHG",
    "516160.XSHG", "159995.XSHE", "513100.XSHG", "513050.XSHG", "159949.XSHE",
    "588000.XSHG", "512260.XSHG", "510500.XSHG",
]


# ============= å›æµ‹å‡½æ•° =============

def run_backtest_with_config(
    strategy_key: str,
    start_date: str,
    end_date: str,
    frequency: str = "monthly",
    top_n: int = 2,
    observation_period: int = 2,
    correlation_threshold: float = 0.70,
) -> Dict[str, Any]:
    """æ‰§è¡Œå•æ¬¡å›æµ‹å¹¶è¿”å›è¯¦ç»†ç»“æœ"""
    
    refresh_analysis_presets()
    preset = ANALYSIS_PRESETS.get(strategy_key)
    if not preset:
        return {"error": f"ç­–ç•¥ {strategy_key} ä¸å­˜åœ¨"}

    config = AnalysisConfig(
        start_date=start_date,
        end_date=end_date,
        etfs=ALL_CODES,
        momentum=preset.momentum_config(),
        corr_window=preset.corr_window,
        chop_window=preset.chop_window,
        trend_window=preset.trend_window,
        rank_change_lookback=preset.rank_lookback,
        make_plots=False,
    )

    result = analyze(config)

    # æå–æ•°æ®
    close_df = pd.DataFrame({code: data["close"] for code, data in result.raw_data.items()})
    close_df = close_df.sort_index().dropna(how="all")

    if close_df.empty:
        return {"error": "ä»·æ ¼æ•°æ®ä¸ºç©º"}

    returns_df = close_df.pct_change().fillna(0)
    momentum_df = result.momentum_scores

    # æ•°æ®å¯¹é½
    common_dates = close_df.index.intersection(momentum_df.index)
    if len(common_dates) < 20:
        return {"error": f"æ•°æ®é‡å æœŸè¿‡çŸ­({len(common_dates)}å¤©)"}

    close_df = close_df.loc[common_dates]
    returns_df = returns_df.loc[common_dates]
    momentum_df = momentum_df.loc[common_dates]

    # è°ƒä»“æ—¥æœŸ
    if frequency == "weekly":
        rebalance_dates = close_df.resample("W-FRI").last().index
    else:
        rebalance_dates = close_df.resample("ME").last().index

    # å›æµ‹é€»è¾‘
    weights = pd.DataFrame(0.0, index=close_df.index, columns=close_df.columns)
    current_codes = []
    observation_counter = {}
    rebalance_log = []  # è®°å½•æ¯æ¬¡è°ƒä»“

    for date in close_df.index:
        if date in rebalance_dates:
            scores = momentum_df.loc[date].dropna()
            top_codes = scores.sort_values(ascending=False).head(top_n).index.tolist()

            # è§‚å¯ŸæœŸé€»è¾‘
            next_hold = []
            current_set = set(current_codes)
            top_set = set(top_codes)

            for code in current_set:
                if code in top_set:
                    observation_counter[code] = 0
                    next_hold.append(code)
                else:
                    observation_counter[code] = observation_counter.get(code, 0) + 1
                    if observation_period <= 0 or observation_counter[code] >= observation_period:
                        pass
                    else:
                        next_hold.append(code)

            # è¡¥è¶³ç©ºä½
            if len(next_hold) < top_n:
                for code in top_codes:
                    if code not in next_hold:
                        next_hold.append(code)
                    if len(next_hold) >= top_n:
                        break

            # è®°å½•è°ƒä»“
            if set(next_hold) != set(current_codes):
                rebalance_log.append({
                    "date": date,
                    "from": current_codes.copy(),
                    "to": next_hold.copy(),
                })

            current_codes = [c for c in next_hold if c in close_df.columns]

        if current_codes:
            weights.loc[date, current_codes] = 1.0 / len(current_codes)

    # è®¡ç®—æ”¶ç›Š
    portfolio_returns = (weights.shift().fillna(0) * returns_df).sum(axis=1)
    cumulative = (1 + portfolio_returns).cumprod()

    # æ€§èƒ½æŒ‡æ ‡
    total_return = cumulative.iloc[-1] - 1 if not cumulative.empty else 0
    trading_days = len(portfolio_returns)

    if trading_days >= 180:
        ann_return = (1 + total_return) ** (252 / trading_days) - 1 if trading_days > 0 else 0
        sharpe = (portfolio_returns.mean() / portfolio_returns.std()) * np.sqrt(252) if portfolio_returns.std() != 0 else 0
    else:
        ann_return = np.nan
        sharpe = np.nan

    drawdown = cumulative / cumulative.cummax() - 1 if not cumulative.empty else pd.Series(dtype=float)
    max_drawdown = drawdown.min() if not drawdown.empty else 0

    # æ¢æ‰‹ç‡
    weight_changes = weights.diff().abs().sum(axis=1)
    turnover_per_period = weight_changes.mean()
    periods_per_year = 52 if frequency == "weekly" else 12
    annual_turnover = turnover_per_period * periods_per_year

    # æœ€æ–°æŒä»“
    latest_holdings = weights.iloc[-1]
    latest_holdings = latest_holdings[latest_holdings > 0].to_dict()

    return {
        "total_return": float(total_return),
        "annualized_return": float(ann_return) if np.isfinite(ann_return) else np.nan,
        "sharpe_ratio": float(sharpe) if np.isfinite(sharpe) else np.nan,
        "max_drawdown": float(max_drawdown),
        "annual_turnover": float(annual_turnover),
        "trading_days": trading_days,
        "rebalance_count": len(rebalance_log),
        "latest_holdings": latest_holdings,
        "cumulative_series": cumulative,
        "rebalance_log": rebalance_log[-10:],  # æœ€è¿‘10æ¬¡è°ƒä»“
    }


def calculate_benchmark_performance(benchmark_code: str, start_date: str, end_date: str) -> Dict[str, Any]:
    """è®¡ç®—åŸºå‡†æŒ‡æ•°è¡¨ç°"""
    
    config = AnalysisConfig(
        start_date=start_date,
        end_date=end_date,
        etfs=[benchmark_code],
        make_plots=False,
    )

    result = analyze(config)
    
    if benchmark_code not in result.raw_data:
        return {"error": f"åŸºå‡† {benchmark_code} æ•°æ®ç¼ºå¤±"}

    close = result.raw_data[benchmark_code]["close"]
    returns = close.pct_change().fillna(0)
    cumulative = (1 + returns).cumprod()

    total_return = cumulative.iloc[-1] - 1 if not cumulative.empty else 0
    trading_days = len(returns)

    if trading_days >= 180:
        ann_return = (1 + total_return) ** (252 / trading_days) - 1 if trading_days > 0 else 0
        sharpe = (returns.mean() / returns.std()) * np.sqrt(252) if returns.std() != 0 else 0
    else:
        ann_return = np.nan
        sharpe = np.nan

    drawdown = cumulative / cumulative.cummax() - 1
    max_drawdown = drawdown.min() if not drawdown.empty else 0

    return {
        "total_return": float(total_return),
        "annualized_return": float(ann_return) if np.isfinite(ann_return) else np.nan,
        "sharpe_ratio": float(sharpe) if np.isfinite(sharpe) else np.nan,
        "max_drawdown": float(max_drawdown),
    }


# ============= ä¸»æµç¨‹ =============

def main():
    parser = argparse.ArgumentParser(description="æœ€ä¼˜ç­–ç•¥éªŒè¯ä¸é•¿æœŸå›æµ‹")
    parser.add_argument("--strategy", type=str, default="twelve-minus-one", help="ç­–ç•¥åç§°")
    parser.add_argument("--period", type=str, default="10y", choices=["1y", "3y", "5y", "10y", "all"], help="å›æµ‹å‘¨æœŸ")
    parser.add_argument("--compare-all", action="store_true", help="å¯¹æ¯”æ‰€æœ‰ç­–ç•¥")
    
    args = parser.parse_args()

    # ç¡®å®šå›æµ‹åŒºé—´
    end_date = datetime.now().strftime("%Y-%m-%d")
    if args.period == "1y":
        start_date = (datetime.now() - timedelta(days=365)).strftime("%Y-%m-%d")
    elif args.period == "3y":
        start_date = (datetime.now() - timedelta(days=365*3)).strftime("%Y-%m-%d")
    elif args.period == "5y":
        start_date = (datetime.now() - timedelta(days=365*5)).strftime("%Y-%m-%d")
    elif args.period == "10y":
        start_date = (datetime.now() - timedelta(days=365*10)).strftime("%Y-%m-%d")
    else:
        start_date = "2015-01-01"

    print("\n" + "="*70)
    print(f"æœ€ä¼˜ç­–ç•¥éªŒè¯ - {args.strategy}")
    print("="*70)
    print(f"å›æµ‹åŒºé—´: {start_date} è‡³ {end_date}")
    print(f"é…ç½®: æœˆåº¦è°ƒä»“ | Top2æŒä»“ | è§‚å¯ŸæœŸ2æœˆ | ç›¸å…³æ€§â‰¤0.70")
    print()

    # è¿è¡Œç­–ç•¥å›æµ‹
    print("æ­£åœ¨å›æµ‹ç­–ç•¥...")
    result = run_backtest_with_config(
        strategy_key=args.strategy,
        start_date=start_date,
        end_date=end_date,
        **{k: v for k, v in RECOMMENDED_CONFIG.items() if k != "strategy"}
    )

    if "error" in result:
        print(f"âŒ å›æµ‹å¤±è´¥: {result['error']}")
        return

    # è®¡ç®—åŸºå‡†è¡¨ç°
    print("æ­£åœ¨è®¡ç®—åŸºå‡†æŒ‡æ•°...")
    benchmarks = {}
    for name, code in BENCHMARK_CODES.items():
        bm_result = calculate_benchmark_performance(code, start_date, end_date)
        if "error" not in bm_result:
            benchmarks[name] = bm_result

    # è¾“å‡ºç»“æœ
    print("\n" + "-"*70)
    print("ğŸ“Š ç­–ç•¥è¡¨ç°")
    print("-"*70)
    print(f"ç´¯è®¡æ”¶ç›Š:     {result['total_return']:>8.2%}")
    print(f"å¹´åŒ–æ”¶ç›Š:     {result['annualized_return']:>8.2%}")
    print(f"å¤æ™®æ¯”ç‡:     {result['sharpe_ratio']:>8.2f}")
    print(f"æœ€å¤§å›æ’¤:     {result['max_drawdown']:>8.2%}")
    print(f"å¹´åŒ–æ¢æ‰‹ç‡:   {result['annual_turnover']:>8.2f}")
    print(f"è°ƒä»“æ¬¡æ•°:     {result['rebalance_count']:>8d}")

    print("\n" + "-"*70)
    print("ğŸ“ˆ åŸºå‡†å¯¹æ¯”")
    print("-"*70)
    print(f"{'æŒ‡æ•°':<12} {'å¹´åŒ–æ”¶ç›Š':>10} {'å¤æ™®æ¯”ç‡':>10} {'æœ€å¤§å›æ’¤':>10} {'è¶…é¢æ”¶ç›Š':>10}")
    print("-"*70)
    
    for name, bm in benchmarks.items():
        excess = result['annualized_return'] - bm['annualized_return']
        print(f"{name:<12} {bm['annualized_return']:>9.2%} {bm['sharpe_ratio']:>10.2f} "
              f"{bm['max_drawdown']:>10.2%} {excess:>9.2%}")

    print("\n" + "-"*70)
    print("ğŸ’¼ å½“å‰æŒä»“å»ºè®®")
    print("-"*70)
    if result['latest_holdings']:
        for code, weight in result['latest_holdings'].items():
            print(f"{code}: {weight:.1%}")
    else:
        print("æ— æŒä»“")

    print("\nâœ“ éªŒè¯å®Œæˆï¼")


if __name__ == "__main__":
    main()

